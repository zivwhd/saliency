{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3462c9f-4bb5-4f05-a8b4-c407a3ad5ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad648508-9790-4cb9-8804-8ee37b65f8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tcloss(exp, masks, preds):    \n",
    "    diff = (exp.unsqueeze(0) * masks).sum(dim=1) - pred\n",
    "    mse = (diff * diff).mean()\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ead2b05-1842-4336-89ed-724dd7f8051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "REP = 9\n",
    "masks = torch.tensor([[0,0,1]]+ [[0,1,1]] * REP)\n",
    "pred = torch.tensor([1.0] + [1.0] * REP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "236e0135-97b9-4516-8a72-1dddccba1612",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = torch.tensor([1.0,1.0,1.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "231c7239-6e8a-4875-8b46-53bd2abeb07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] step: grad=[0.14, -0.05, -0.09]; base=[0.85, 1.05, 1.09]; exp=[0.28, 0.35, 0.36];\n",
      "[1] step: grad=[0.13, -0.03, -0.07]; base=[0.71, 1.08, 1.17]; exp=[0.24, 0.36, 0.39];\n",
      "[2] step: grad=[0.12, -0.01, -0.05]; base=[0.58, 1.1, 1.23]; exp=[0.2, 0.37, 0.42];\n",
      "[3] step: grad=[0.11, 0.0, -0.04]; base=[0.47, 1.11, 1.27]; exp=[0.16, 0.38, 0.44];\n",
      "[4] step: grad=[0.1, 0.0, -0.03]; base=[0.36, 1.11, 1.31]; exp=[0.13, 0.39, 0.47];\n",
      "[5] step: grad=[0.09, 0.0, -0.03]; base=[0.27, 1.1, 1.34]; exp=[0.1, 0.4, 0.49];\n",
      "[6] step: grad=[0.07, 0.01, -0.02]; base=[0.19, 1.09, 1.37]; exp=[0.07, 0.41, 0.51];\n",
      "[7] step: grad=[0.06, 0.01, -0.02]; base=[0.13, 1.07, 1.39]; exp=[0.05, 0.41, 0.53];\n",
      "[8] step: grad=[0.05, 0.01, -0.01]; base=[0.08, 1.06, 1.41]; exp=[0.03, 0.41, 0.55];\n",
      "[9] step: grad=[0.04, 0.01, -0.01]; base=[0.03, 1.04, 1.43]; exp=[0.01, 0.41, 0.56];\n",
      "[10] step: grad=[0.03, 0.01, -0.01]; base=[0.0, 1.02, 1.44]; exp=[0.0, 0.41, 0.58];\n",
      "[20] step: grad=[0.0, 0.01, -0.01]; base=[-0.05, 0.83, 1.56]; exp=[-0.02, 0.35, 0.66];\n",
      "[30] step: grad=[0.0, 0.01, 0.0]; base=[-0.05, 0.65, 1.64]; exp=[-0.02, 0.29, 0.73];\n",
      "[40] step: grad=[0.0, 0.01, 0.0]; base=[-0.04, 0.49, 1.7]; exp=[-0.01, 0.22, 0.79];\n",
      "[50] step: grad=[0.0, 0.01, 0.0]; base=[-0.03, 0.35, 1.73]; exp=[-0.01, 0.17, 0.84];\n",
      "[60] step: grad=[0.0, 0.01, 0.0]; base=[-0.02, 0.23, 1.75]; exp=[-0.01, 0.12, 0.89];\n",
      "[70] step: grad=[0.0, 0.0, 0.0]; base=[-0.01, 0.15, 1.76]; exp=[0.0, 0.08, 0.92];\n",
      "[80] step: grad=[0.0, 0.0, 0.0]; base=[0.0, 0.09, 1.77]; exp=[0.0, 0.05, 0.95];\n",
      "[90] step: grad=[0.0, 0.0, 0.0]; base=[0.0, 0.05, 1.77]; exp=[0.0, 0.03, 0.97];\n",
      "[100] step: grad=[0.0, 0.0, 0.0]; base=[0.0, 0.03, 1.77]; exp=[0.0, 0.01, 0.98];\n",
      "[200] step: grad=[0.0, 0.0, 0.0]; base=[0.0, 0.0, 1.77]; exp=[0.0, 0.0, 0.99];\n",
      "[300] step: grad=[0.0, 0.0, 0.0]; base=[0.0, 0.0, 1.77]; exp=[0.0, 0.0, 0.99];\n",
      "[400] step: grad=[0.0, 0.0, 0.0]; base=[0.0, 0.0, 1.77]; exp=[0.0, 0.0, 1.0];\n",
      "[500] step: grad=[0.0, 0.0, 0.0]; base=[0.0, 0.0, 1.77]; exp=[0.0, 0.0, 1.0];\n",
      "[600] step: grad=[0.0, 0.0, 0.0]; base=[0.0, 0.0, 1.77]; exp=[0.0, 0.0, 1.0];\n",
      "[700] step: grad=[0.0, 0.0, 0.0]; base=[0.0, 0.0, 1.77]; exp=[0.0, 0.0, 1.0];\n",
      "[800] step: grad=[0.0, 0.0, 0.0]; base=[0.0, 0.0, 1.77]; exp=[0.0, 0.0, 1.0];\n",
      "[900] step: grad=[0.0, 0.0, 0.0]; base=[0.0, 0.0, 1.77]; exp=[0.0, 0.0, 1.0];\n"
     ]
    }
   ],
   "source": [
    "def tr(x, r=100):\n",
    "    return [int(n*r)/r for n in  x.tolist()] \n",
    "\n",
    "for idx in range(1000):\n",
    "    if base.grad is not None:\n",
    "        base.grad.zero_()  # Clear gradients if they exist\n",
    "    \n",
    "    exp = base / base.sum()  # Normalization\n",
    "    loss = tcloss(exp, masks, pred)  # Compute loss\n",
    "    loss.backward()  # Backpropagation to compute gradients\n",
    "    \n",
    "    grads = base.grad  # Access the computed gradient\n",
    "    base = (base - 1 * grads).detach().requires_grad_(True)  # Update step with re-enabled gradients\n",
    "\n",
    "    # Optionally, for monitoring\n",
    "    exp = base / base.sum()\n",
    "    if idx < 10  or (idx < 100 and idx % 10 ==0) or idx % 100 == 0:\n",
    "        print(f\"[{idx}] step: grad={tr(grads)}; base={tr(base)}; exp={tr(exp)};\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2630a6a9-b36e-427a-985e-fad45e94e086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23909a3-072a-4e22-8372-964be6a5ef3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
